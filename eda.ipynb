{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e25ea09-74d6-47e6-bad6-e922f52c3532",
   "metadata": {},
   "source": [
    "# Personal Information\n",
    "Name: **Mayla Kersten**\n",
    "\n",
    "StudentID: **12393983**\n",
    "\n",
    "Email: [**maylakersten@student.uva.nl**](maylakersten@student.uva.nl)\n",
    "\n",
    "Submitted on: **19.03.2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf6243-adfe-4eb8-bba3-bb2835079abd",
   "metadata": {},
   "source": [
    "# Data Context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197c2ee5",
   "metadata": {},
   "source": [
    "To compare the effect of integrating argument mining in fake news detection we will compare results to the study by Khan et al. (2021): \"A Benchmark Study of Machine Learning Models for Online Fake News Detection\". \n",
    "\n",
    "To replicate this we use the following same 2 datasets:\n",
    "\n",
    "- *Fake and Real News* dataset from George McIntire (2017) comprising news from the 2016 US election cycle. Not open-source, received via e-mail.\n",
    "\n",
    "- *Liar* by Wang in \"Liar, Liar Pants on Fire\" (2017) consists of human-labeled short statements from [Politifact](www.politifact.com).\n",
    "\n",
    "We also introduce another dataset:\n",
    "\n",
    "- *Fake or Real News* from Bisaillon from [Kaggle] comprising fake news and real news articles in political context from 2015 to 2018.\n",
    "\n",
    "My [GitHub repository](https://github.com/himayla/fallacy_fake_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833d964-56e1-49c7-8172-7435357624aa",
   "metadata": {},
   "source": [
    "# Data Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534317db-d881-4e33-a358-754e2881e8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mayla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mayla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt\")\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582b299-f599-4140-a454-bcbfdeeb273f",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0cf9be-2cac-4227-957f-ad893212e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fake and Real News dataset by Mcintire\n",
    "fake_real = pd.read_csv(\"data/mcintire/fake_and_real_news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Liar dataset by Wang\n",
    "labels = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
    "\n",
    "liar_train = pd.read_csv(\"data/liar/train.tsv\", sep=\"\\t\", names=labels)\n",
    "liar_valid = pd.read_csv(\"data/liar/valid.tsv\", sep=\"\\t\", names=labels)\n",
    "liar_test = pd.read_csv(\"data/liar/test.tsv\", sep=\"\\t\", names=labels)\n",
    "\n",
    "liar = pd.concat([liar_train, liar_valid, liar_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee308d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fake or Real news from Kaggle\n",
    "df_real = pd.read_csv(\"data/kaggle/True.csv\")\n",
    "df_real[\"label\"] = \"REAL\"\n",
    "\n",
    "df_fake = pd.read_csv(\"data/kaggle/Fake.csv\")\n",
    "df_fake[\"label\"] = \"FAKE\"\n",
    "\n",
    "kaggle = pd.concat([df_real, df_fake], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87445f",
   "metadata": {},
   "source": [
    "We perform similar data wrangling steps as Khan et al. (2021). In **Liar** the 6 labels (ranging from true to false) are converted to either true or false: \n",
    "- true, half-true, and mostly-true get labeled *REAL*\n",
    "- barely-true, pants-fire, and false get labeled *FAKE*.\n",
    "\n",
    "The dataset additional information is removed, because  because in real-life scenarios we may not always have such metadata (in i.e. `job_title`) available.\n",
    "\n",
    "We also remove such information from **Fake and Real News** and **Kaggle**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0522c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels\n",
    "liar[\"label\"] = liar[\"label\"].map({\n",
    "    \"true\": \"REAL\",\n",
    "    \"half-true\": \"REAL\",\n",
    "    \"mostly-true\": \"REAL\",\n",
    "    \"barely-true\": \"FAKE\",\n",
    "    \"pants-fire\": \"FAKE\",\n",
    "    \"false\": \"FAKE\"\n",
    "})\n",
    "\n",
    "# Remove metadata from datasets\n",
    "fake_real = fake_real.drop(columns=[\"idd\", \"title\"])\n",
    "liar = liar[[\"label\", \"statement\"]]\n",
    "kaggle = kaggle[[\"text\", \"label\"]]\n",
    "\n",
    "# Rename column to match the other datasets\n",
    "liar = liar.rename(columns={\"statement\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a2d847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th># Fake</th>\n",
       "      <th># Real</th>\n",
       "      <th>% Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fake and Real News</th>\n",
       "      <td>4594</td>\n",
       "      <td>2297</td>\n",
       "      <td>2297</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liar</th>\n",
       "      <td>12791</td>\n",
       "      <td>5657</td>\n",
       "      <td>7134</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake or Real News</th>\n",
       "      <td>44898</td>\n",
       "      <td>23481</td>\n",
       "      <td>21417</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total  # Fake  # Real % Fake\n",
       "Fake and Real News   4594    2297    2297   0.50\n",
       "Liar                12791    5657    7134   0.44\n",
       "Fake or Real News   44898   23481   21417   0.52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def n_label(df, label):\n",
    "    \"\"\" Returns number of examples with a specific label \"\"\"\n",
    "    return len(df[df[\"label\"] == label])\n",
    "\n",
    "# Compare datasets\n",
    "corpora_stats = pd.DataFrame(\n",
    "    index=[\"Fake and Real News\", \"Liar\", \"Fake or Real News\"], \n",
    "    data={\n",
    "    \"Total\": [fake_real.shape[0], liar.shape[0], kaggle.shape[0]], \n",
    "    \"# Fake\": [n_label(fake_real, \"FAKE\"), n_label(liar, \"FAKE\"), n_label(kaggle, \"FAKE\")],\n",
    "    \"# Real\": [n_label(fake_real, \"REAL\"), n_label(liar, \"REAL\"), n_label(kaggle, \"REAL\")],\n",
    "    \"% Fake\": [\"{:.2f}\".format(n_label(fake_real, \"FAKE\") / len(fake_real)), \n",
    "               \"{:.2f}\".format(n_label(liar, \"FAKE\") / len(liar)), \n",
    "               \"{:.2f}\".format(n_label(kaggle, \"FAKE\") / len(kaggle))],\n",
    "    }\n",
    ")\n",
    "\n",
    "display(corpora_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b779c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "{} &  Total &  \\# Fake &  \\# Real & \\% Fake \\\\\n",
      "\\midrule\n",
      "Fake and Real News &   4594 &    2297 &    2297 &   0.50 \\\\\n",
      "Liar               &  12791 &    5657 &    7134 &   0.44 \\\\\n",
      "Fake or Real News  &  44898 &   23481 &   21417 &   0.52 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overleaf\n",
    "print(corpora_stats.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df9546-a6d7-4678-aca6-cd13d5f3c79a",
   "metadata": {},
   "source": [
    "### Analysis corpora level:\n",
    "\n",
    "The **Fake and Real News** dataset from Mcintire (2017) comprises 4,594 rows and 4 fields, `idd`, `title`, `text`, and `label`. This dataset is currently not open-source; I have received this dataset from George McIntire via e-mail. Interestingly enough, 4,594 news articles is a lot less than the 6,300 described by Khan et al. (2021). \n",
    "\n",
    "The information from the columns `idd` and `title` was removed. There is an equal allocation (50%) of fake and real news.\n",
    "\n",
    "The dataset **Liar** is used in the study \"Liar, Liar Pants on Fire\" by William Yang Wang (2017) and consists of 12,791 human-labeled short statements from [Politifact](www.politifact.com). The dataset can be downloaded from [here](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip). The zip folder consists 3 TSV files: a train, validation, and test set. To compare the datasets on macro-level these were combined. Similar wrangling steps as Khan et al. (2021) were conducted: the labels were converted from 6 to 2 and metadata was removed. The column `statement` is renamed to `text`, so it is in line with the other datasets. The allocation of fake to real news is 44%.\n",
    "\n",
    "The **Kaggle** dataset contains 44,898 news articles. The `title` column was removed. There is an equal allocation (52%) of fake and real news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df05ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type text</th>\n",
       "      <th>% Unique</th>\n",
       "      <th>% Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fake and Real News</th>\n",
       "      <td>object</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liar</th>\n",
       "      <td>object</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake or Real News</th>\n",
       "      <td>object</td>\n",
       "      <td>86.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Type text  % Unique  % Missing\n",
       "Fake and Real News    object      96.0        0.0\n",
       "Liar                  object      99.8        0.0\n",
       "Fake or Real News     object      86.1        0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_stats = pd.DataFrame(\n",
    "    index=[\"Fake and Real News\", \"Liar\", \"Fake or Real News\"], \n",
    "    data={\n",
    "    \"Type text\": [fake_real[\"text\"].dtype, liar[\"text\"].dtype, kaggle[\"text\"].dtype], \n",
    "    \"% Unique\": [round(len(fake_real[\"text\"].unique()) / len(fake_real[\"text\"]) * 100, 1),\n",
    "                 round(len(liar[\"text\"].unique()) / len(liar[\"text\"]) * 100, 1),\n",
    "                 round(len(kaggle[\"text\"].unique()) / len(kaggle[\"text\"]) * 100, 1)],\n",
    "    \"% Missing\": [round((fake_real[\"text\"].isna().sum() / len(fake_real[\"text\"])) * 100, 2), \n",
    "                  round((liar[\"text\"].isna().sum() / len(liar[\"text\"])) * 100, 2), \n",
    "                  round((kaggle[\"text\"].isna().sum() / len(kaggle[\"text\"])) * 100, 2)]\n",
    "    }\n",
    ")\n",
    "text_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c655a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "{} & Type text &  \\% Unique &  \\% Missing \\\\\n",
      "\\midrule\n",
      "Fake and Real News &    object &      96.0 &        0.0 \\\\\n",
      "Liar               &    object &      99.8 &        0.0 \\\\\n",
      "Fake or Real News  &    object &      86.1 &        0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_stats.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a8b3d",
   "metadata": {},
   "source": [
    "There are no values missing, there are however some duplicates. In Khan et al. (2021) removal of any duplicates is not mentioned. We will therefore only remove them from the new Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be7f1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = kaggle.drop_duplicates(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522eef6a",
   "metadata": {},
   "source": [
    "This changes the count of **Kaggle**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf04c7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th># Fake</th>\n",
       "      <th># Real</th>\n",
       "      <th>% Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fake and Real News</th>\n",
       "      <td>4594</td>\n",
       "      <td>2297</td>\n",
       "      <td>2297</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liar</th>\n",
       "      <td>12791</td>\n",
       "      <td>5657</td>\n",
       "      <td>7134</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake or Real News</th>\n",
       "      <td>38646</td>\n",
       "      <td>17454</td>\n",
       "      <td>21192</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total  # Fake  # Real % Fake\n",
       "Fake and Real News   4594    2297    2297   0.50\n",
       "Liar                12791    5657    7134   0.44\n",
       "Fake or Real News   38646   17454   21192   0.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "{} &  Total &  \\# Fake &  \\# Real & \\% Fake \\\\\n",
      "\\midrule\n",
      "Fake and Real News &   4594 &    2297 &    2297 &   0.50 \\\\\n",
      "Liar               &  12791 &    5657 &    7134 &   0.44 \\\\\n",
      "Fake or Real News  &  38646 &   17454 &   21192 &   0.45 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare datasets\n",
    "corpora_stats_after = pd.DataFrame(\n",
    "    index=[\"Fake and Real News\", \"Liar\", \"Fake or Real News\"], \n",
    "    data={\n",
    "    \"Total\": [fake_real.shape[0], liar.shape[0], kaggle.shape[0]], \n",
    "    \"# Fake\": [n_label(fake_real, \"FAKE\"), n_label(liar, \"FAKE\"), n_label(kaggle, \"FAKE\")],\n",
    "    \"# Real\": [n_label(fake_real, \"REAL\"), n_label(liar, \"REAL\"), n_label(kaggle, \"REAL\")],\n",
    "    \"% Fake\": [\"{:.2f}\".format(n_label(fake_real, \"FAKE\") / len(fake_real)), \n",
    "               \"{:.2f}\".format(n_label(liar, \"FAKE\") / len(liar)), \n",
    "               \"{:.2f}\".format(n_label(kaggle, \"FAKE\") / len(kaggle))],\n",
    "    }\n",
    ")\n",
    "\n",
    "display(corpora_stats_after)\n",
    "\n",
    "print(corpora_stats_after.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2737af6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type text</th>\n",
       "      <th>% Unique</th>\n",
       "      <th>% Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fake and Real News</th>\n",
       "      <td>object</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liar</th>\n",
       "      <td>object</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake or Real News</th>\n",
       "      <td>object</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Type text  % Unique  % Missing\n",
       "Fake and Real News    object      96.0        0.0\n",
       "Liar                  object      99.8        0.0\n",
       "Fake or Real News     object     100.0        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "{} & Type text &  \\% Unique &  \\% Missing \\\\\n",
      "\\midrule\n",
      "Fake and Real News &    object &      96.0 &        0.0 \\\\\n",
      "Liar               &    object &      99.8 &        0.0 \\\\\n",
      "Fake or Real News  &    object &     100.0 &        0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_stats_after = pd.DataFrame(\n",
    "    index=[\"Fake and Real News\", \"Liar\", \"Fake or Real News\"], \n",
    "    data={\n",
    "    \"Type text\": [fake_real[\"text\"].dtype, liar[\"text\"].dtype, kaggle[\"text\"].dtype], \n",
    "    \"% Unique\": [round(len(fake_real[\"text\"].unique()) / len(fake_real[\"text\"]) * 100, 1),\n",
    "                 round(len(liar[\"text\"].unique()) / len(liar[\"text\"]) * 100, 1),\n",
    "                 round(len(kaggle[\"text\"].unique()) / len(kaggle[\"text\"]) * 100, 1)],\n",
    "    \"% Missing\": [round((fake_real[\"text\"].isna().sum() / len(fake_real[\"text\"])) * 100, 2), \n",
    "                  round((liar[\"text\"].isna().sum() / len(liar[\"text\"])) * 100, 2), \n",
    "                  round((kaggle[\"text\"].isna().sum() / len(kaggle[\"text\"])) * 100, 2)]\n",
    "    }\n",
    ")\n",
    "display(text_stats_after)\n",
    "\n",
    "print(text_stats_after.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78764ad",
   "metadata": {},
   "source": [
    "We now continue the exploration on variable level. We start with preprocessing the text. We try to replicate the preprocessing steps from Khan et al. (2021). In their paper they describe the following steps: \n",
    "1. Remove IP and URL adresses from raw text\n",
    "2. Remove stopwords in raw text\n",
    "3. Correct the spelling in raw text\n",
    "4. Remove suffices by stemming\n",
    "5. Rejoin words tokens by white space\n",
    "\n",
    "Exact information on what stopwords are removed, which spelling corrector is deployed, how the suffices are removed is lacking. So for this, decisions have been made based on popular tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773b109",
   "metadata": {},
   "source": [
    "**N.B. The preprocessing of the data takes so many hours that unfortunately I have decided to for demonstration purposes in this EDA document to limit the sizes of the data sets sizes to 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba3bf469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLTK stopwords and Snowball stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "243a8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text):\n",
    "    \"\"\" Perform preprocessing\"\"\"\n",
    "    # Remove urls and IPs\n",
    "    txt = raw_text.replace(r\"http://\\S+|https://\\S++\", \"\").replace(r\"\\.[0]*\", \"\")\n",
    "\n",
    "    word_tokens = word_tokenize(txt)\n",
    "\n",
    "    # Remove stop words \n",
    "    sent = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    # Replace different colons to regular ones\n",
    "    sent = [w.replace(\"”\", \"\\\"\").replace(\"“\", \"\\\"\").replace(\"’\", \"\\\"\").replace(\"...\", \".\") for w in sent]\n",
    "\n",
    "    # Remove punctuation and split every text by white space\n",
    "    sent = ' '.join([w for w in sent if w not in string.punctuation])\n",
    "\n",
    "    # Correct spelling of words\n",
    "    doc = TextBlob(sent)\n",
    "    corrected = doc.correct()\n",
    "\n",
    "    # Remove suffices by stemming\n",
    "    stemmed = [stemmer.stem(w) for w in corrected.split()]\n",
    "\n",
    "    return ' '.join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d883454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 takes 16 minutes\n",
    "fake_real_s = fake_real.loc[:100].copy()\n",
    "fake_real_s.loc[:,\"clean_text\"] = fake_real_s.apply(lambda x: preprocess(x[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "130e7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 takes <1 minutes\n",
    "liar_s = liar[:100].copy()\n",
    "liar_s.loc[:,\"clean_text\"] = liar_s.apply(lambda x: preprocess(x[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75873693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 takes 13 min\n",
    "kaggle_s = kaggle.loc[:100].copy()\n",
    "kaggle_s.loc[:,\"clean_text\"] = kaggle_s.apply(lambda x: preprocess(x[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c70a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write clean data out\n",
    "fake_real_s.to_csv(\"data/clean/100_fake_real.csv\")\n",
    "liar_s.to_csv(\"data/clean/100_liar.csv\")\n",
    "kaggle_s.to_csv(\"data/clean/100_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ccff7",
   "metadata": {},
   "source": [
    "We will now look at the length of the texts in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a07ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg # Words</th>\n",
       "      <th>Max # Words</th>\n",
       "      <th>Min # Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fake and Real News</th>\n",
       "      <td>2804.822</td>\n",
       "      <td>10180</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liar</th>\n",
       "      <td>65.760</td>\n",
       "      <td>141</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake or Real News</th>\n",
       "      <td>1680.525</td>\n",
       "      <td>1680</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Avg # Words  Max # Words  Min # Words\n",
       "Fake and Real News    2804.822        10180           55\n",
       "Liar                    65.760          141           14\n",
       "Fake or Real News     1680.525         1680          217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_fake = fake_real_s['clean_text'].str.len()\n",
    "len_liar = liar_s[\"clean_text\"].str.len()\n",
    "len_kaggle = kaggle_s[\"clean_text\"].str.len()\n",
    "\n",
    "variable_stats = pd.DataFrame(\n",
    "    index=[\"Fake and Real News\", \"Liar\", \"Fake or Real News\"], \n",
    "    data={\n",
    "    \"Avg # Words\": [len_fake.mean(), len_liar.mean(), len_kaggle.mean()],\n",
    "    \"Max # Words\":[len_fake.max(), len_liar.max(), len_kaggle.mean()],\n",
    "    \"Min # Words\":[len_fake.min(), len_liar.min(), len_kaggle.min()]\n",
    "    }\n",
    "    )\n",
    "\n",
    "# Format dataframe\n",
    "variable_stats[\"Avg # Words\"] = variable_stats['Avg # Words'].map('{:.3f}'.format)\n",
    "variable_stats[\"Max # Words\"] = variable_stats['Max # Words'].astype(int)\n",
    "variable_stats[\"Min # Words\"] = variable_stats['Min # Words'].astype(int)\n",
    "\n",
    "display(variable_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dba10e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "{} & Avg \\# Words &  Max \\# Words &  Min \\# Words \\\\\n",
      "\\midrule\n",
      "Fake and Real News &    2804.822 &        10180 &           55 \\\\\n",
      "Liar               &      65.760 &          141 &           14 \\\\\n",
      "Fake or Real News  &    1680.525 &         1680 &          217 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(variable_stats.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d31e2",
   "metadata": {},
   "source": [
    "There is nothing mentioned about a minimum amount of words in news articles. We decide less than 10 words, is not a good enough example. So we remove these from the **Kaggle** dataset. For the other 2 datasets we do not od this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7351f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "less = kaggle_s[kaggle_s[\"clean_text\"].str.len() < 10]\n",
    "kaggle_s = kaggle_s.drop(less.index)\n",
    "\n",
    "len_kaggle = kaggle_s[\"clean_text\"].str.len()\n",
    "\n",
    "kaggle_stats = pd.DataFrame(\n",
    "    index=[\"Avg # Words\", \"Max # Words\", \"Min # Words\"],\n",
    "    data={\n",
    "    \"Text\": [len_kaggle.mean(), len_kaggle.max(), len_kaggle.min()]\n",
    "    }\n",
    ")\n",
    "\n",
    "display(kaggle_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015210c6",
   "metadata": {},
   "source": [
    "### Analysis variable level:\n",
    "\n",
    "The texts in the 3 datasets were similarly preprocessed. The taken steps were based on Khan et al. (2021), however because of the lack of details executive decisions were made. NLTK's SnowballStemmer, word_tokenizer, and stopwords were deployed.\n",
    "\n",
    "In the **Kaggle** dataset duplicates were removed and examples that were 25 words or less were discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get strings with content\n",
    "fake_real_content = \" \".join(fake_real_s[\"clean_text\"].map(str).to_list())\n",
    "liar_content = \" \".join(liar_s[\"clean_text\"].map(str).to_list())\n",
    "kaggle_content = \" \".join(kaggle_s[\"clean_text\"].map(str).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wordclouds\n",
    "wc_fr = WordCloud(collocations=False, background_color=\"white\").generate(fake_real_content)\n",
    "wc_liar = WordCloud(collocations=False, background_color=\"white\").generate(liar_content)\n",
    "wc_kaggle = WordCloud(collocations=False, background_color=\"white\").generate(kaggle_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dffa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show wordclouds\n",
    "plt.imshow(wc_fr, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wc_liar, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f89326",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wc_kaggle, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c686b55",
   "metadata": {},
   "source": [
    "The wordcloud above shows an overview of the content of the small dataset. In **Fake and Real dataset** there \"S\" seems to be non-contentual. The same is the case in **Liar** with the world \"U\". In **Kaggle** the word said and plump are the most used, which does not provide a lot of information about the content. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4bc7a400e35f160b13ed52195005e41b219907c1be09b125a1c17e685484faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
